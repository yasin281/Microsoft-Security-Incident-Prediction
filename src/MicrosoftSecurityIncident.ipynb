{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63032c23",
   "metadata": {},
   "source": [
    "# Microsoft Security Incident Prediction\n",
    "\n",
    "This notebook provides a comprehensive workflow for predicting security incidents using a real-world dataset from Microsoft. The process includes:\n",
    "\n",
    "1. **Data Acquisition**: Downloading the relevant CSV file containing cybersecurity incident data.\n",
    "2. **Data Preprocessing**: Cleaning and preparing the dataset for analysis, including handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "3. **Data Exploration**: Exploring the dataset to gain insights into its structure, identifying patterns and correlations, and assessing the distribution of key features.\n",
    "4. **Visualizations**: Creating various plots to visualize trends and relationships in the data, which helps in understanding the underlying patterns that could inform predictive models.\n",
    "5. **Model Training**: Training a variety of models, both linear and non-linear, including regression-based approaches and more complex machine learning algorithms such as decision trees and ensemble methods.\n",
    "6. **Results Analysis**: Evaluating model performance using standard metrics like accuracy, precision, recall, and F1 score, with a focus on understanding the trade-offs between different models and identifying the most effective approach for predicting incident severity.\n",
    "\n",
    "This notebook aims to provide valuable insights for cybersecurity operations by leveraging machine learning techniques to predict and classify incidents based on historical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a106467",
   "metadata": {},
   "source": [
    "## Downloading the Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514baec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9435066e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      2\u001b[0m reduced_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicrosoft_Reduced.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(reduced_file_path):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kagglehub import dataset_download\n",
    "\n",
    "def create_reduced_file(original_file_path, reduced_file_path, target_column, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Crea un archivo reducido a partir del archivo original aplicando undersampling estratificado.\n",
    "\n",
    "    :param original_file_path: Ruta al archivo original.\n",
    "    :param reduced_file_path: Ruta donde se guardar치 el archivo reducido.\n",
    "    :param target_column: Nombre de la columna objetivo para estratificaci칩n.\n",
    "    :param sample_size: Tama침o del conjunto reducido.\n",
    "    \"\"\"\n",
    "    df_original = pd.read_csv(original_file_path)\n",
    "    print(f\"El archivo original tiene {len(df_original)} filas.\")\n",
    "    \n",
    "    # Realizar undersampling estratificado\n",
    "    df_reduced, _ = train_test_split(\n",
    "        df_original,\n",
    "        train_size=sample_size,\n",
    "        stratify=df_original[target_column],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    df_reduced.to_csv(reduced_file_path, index=False)\n",
    "    print(f\"Archivo reducido creado con {len(df_reduced)} filas manteniendo proporciones de clases.\")\n",
    "\n",
    "# Configuraci칩n de rutas\n",
    "dataset_folder = os.getcwd()\n",
    "reduced_file_path = os.path.join(dataset_folder, 'microsoft_Reduced.csv')\n",
    "\n",
    "if not os.path.exists(reduced_file_path):\n",
    "    file_path = dataset_download(\"Microsoft/microsoft-security-incident-prediction\")\n",
    "    original_file_path = os.path.join(file_path, \"GUIDE_Test.csv\")\n",
    "    \n",
    "    create_reduced_file(original_file_path, reduced_file_path, target_column='IncidentGrade')\n",
    "else:\n",
    "    df_reduced = pd.read_csv(reduced_file_path)\n",
    "    print(f\"Archivo cargado con {len(df_reduced)} filas.\")\n",
    "\n",
    "print(df_reduced.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7b361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8eba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
